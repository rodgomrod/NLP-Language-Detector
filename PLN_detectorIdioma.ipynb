{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "8460b9a3-586f-4fc7-b851-34ee4fb78ad7"
    }
   },
   "source": [
    "# Detector de idiomas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "4a761ccc-ac8f-4f0b-9fc1-145cd0f3f925"
    }
   },
   "source": [
    "Se va a diseñar un detector de idiomas utilizando recursos de **Machine Learning**. \n",
    "La idea principal es centrarlo en un problema de clasificación, con el que vamos a ayudarnos de una potente herramienta de ML para Python, **Scikit-Learn**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbpresent": {
     "id": "c718f844-42d9-4649-8dea-5f9e046069b9"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from sklearn import cross_validation\n",
    "from pprint import pprint\n",
    "from sklearn import ensemble\n",
    "from sklearn import feature_extraction\n",
    "from sklearn import linear_model\n",
    "from sklearn import pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.gaussian_process import GaussianProcess\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "2a95a74e-9f8e-49a3-88bb-c3bc4b9a820b"
    }
   },
   "source": [
    "Vamos a trabajar con corpus del Parlamento Europeo que se encuentran disponibles en el siguiente enlace:\n",
    "http://www.statmt.org/europarl/\n",
    "\n",
    "Abrimos los diferentes corpus.\n",
    "Aclaramos los idiomas:\n",
    "\n",
    "pl = polaco  \n",
    "it = italiano  \n",
    "es = español  \n",
    "de = alemán  \n",
    "en = inglés  \n",
    "hu = húngaro  \n",
    "pt = portugués  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbpresent": {
     "id": "733e27e0-bc02-4a37-a623-0ce15687e6ea"
    }
   },
   "outputs": [],
   "source": [
    "pl = open('corpus/pl','r', encoding='utf8')\n",
    "it = open('corpus/it','r', encoding='utf8')\n",
    "es = open('corpus/es','r', encoding='utf8')\n",
    "de = open('corpus/de','r', encoding='utf8')\n",
    "en = open('corpus/en','r', encoding='utf8')\n",
    "hu = open('corpus/hu','r', encoding='utf8')\n",
    "pt = open('corpus/pt','r', encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbpresent": {
     "id": "77def9c3-587f-4bd8-bee5-e85b7e9539ef"
    }
   },
   "outputs": [],
   "source": [
    "corpus_list = ['pl','it','es','de','en','hu','pt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "726760fe-2a7e-4a2e-adb0-ac394199d00f"
    }
   },
   "source": [
    "Con la variable *size* le vamos a decir al programa la cantidad de frases con las que vamos a trabajar. Para que sea más fácil y todos los idiomas estén igualmente representados, procuraremos que *size* sea múltimo de 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbpresent": {
     "id": "8b8c4c73-1b85-483e-830e-b9071a08d580"
    }
   },
   "outputs": [],
   "source": [
    "size = 4000*7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que solo hemos introducido veintiocho mil frases, o lo que es lo mismo, cuatro mil frases de cada idioma. Hemos tenido que coger un número tan reducido de frases debido a problemas de memoria física, ya que consume muchos recursos resolver este problema con el método que describiremos más adelante, aunque también podrá verse que conseguimos unos resultados muy buenos pese a entrenar con pocas frases en comparación con todas las que tienen los corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "dcc1ce3a-14df-450b-94db-ea2b6acb713b"
    }
   },
   "source": [
    "A continuación vamos a crear el DataFrame que estará constituido simplemente con dos columnas, la primera será una frase y la segunda el idioma de dicha frase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "nbpresent": {
     "id": "6ca225d7-14dc-4ca4-95c8-71eb5c03c40f"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame creado en 0.0419 s\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "\n",
    "leng = []\n",
    "txt = []\n",
    "\n",
    "for j in corpus_list:\n",
    "    n = 0\n",
    "    for i in eval(j):\n",
    "        if n < (size/len(corpus_list)):\n",
    "            if len(i) < 40:\n",
    "                pass\n",
    "            else:\n",
    "                n+=1\n",
    "                txt.append(i[:-1])\n",
    "                leng.append(str(j))\n",
    "        else:\n",
    "             break\n",
    "    eval(j).close()\n",
    "                \n",
    "df = pd.DataFrame()\n",
    "df['texto'] = txt\n",
    "df['idioma'] = leng\n",
    "\n",
    "print(\"DataFrame creado en %0.4f s\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver un pequeño resumen de nuestro DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbpresent": {
     "id": "ebd731b4-ebbd-403c-8ed2-4a6cb7bba449"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto</th>\n",
       "      <th>idioma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>28000</td>\n",
       "      <td>28000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>27189</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Az előző ülés jegyzőkönyvének elfogadása: lásd...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>46</td>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    texto idioma\n",
       "count                                               28000  28000\n",
       "unique                                              27189      7\n",
       "top     Az előző ülés jegyzőkönyvének elfogadása: lásd...     en\n",
       "freq                                                   46   4000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminamos las frases repetidas, ya que no son interesantes para este problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset='texto', keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto</th>\n",
       "      <th>idioma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>27189</td>\n",
       "      <td>27189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>27189</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Signor Presidente, signor Commissario, onorevo...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>3994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    texto idioma\n",
       "count                                               27189  27189\n",
       "unique                                              27189      7\n",
       "top     Signor Presidente, signor Commissario, onorevo...     pt\n",
       "freq                                                    1   3994"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crearemos, a partir del DataFrame, nuestro conjunto de entrenamiento, train, y nuestro conjunto de validación, test.\n",
    "Para realizar esto utilizaremos la herramienta de Scikit-Learn *train_test_split* cuyo parámetro *test_size* nos va a indicar el tamaño del conjunto de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "nbpresent": {
     "id": "ec81db57-acd1-4c13-aa1d-9f495ce4b8f6"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(\n",
    "    df['texto'],\n",
    "    df['idioma'],\n",
    "    test_size=0.3,\n",
    "    random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con la funcion *feature_extraction.text.TfidfVectorizer* podremos separar la frase por palabras, lo que se conoce como *tokenizar*. El parámetro *analyzer='word'* nos indica que vamos a separar por palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "nbpresent": {
     "id": "c4b5f787-bf79-478e-a3f6-052a6d865de7"
    }
   },
   "outputs": [],
   "source": [
    "vectorizer = feature_extraction.text.TfidfVectorizer(\n",
    "    analyzer='word',\n",
    "    ngram_range = (1,2),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se va a entrenar diferentes clasificadores para su evaluación con la métrica *accuracy* y nos quedaremos con el que más acierto presente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando modelo XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
      "       n_jobs=-1, nthread=None, objective='multi:softmax', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "Acierto en redicciones:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/preprocessing/label.py:171: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9680029422581832\n",
      "Entrenando modelo RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=200, n_jobs=-1, oob_score=False,\n",
      "            random_state=None, verbose=0, warm_start=False)\n",
      "Acierto en redicciones:\n",
      "\n",
      "0.9849209268113277\n",
      "Entrenando modelo KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=-1, n_neighbors=7, p=2,\n",
      "           weights='uniform')\n",
      "Acierto en redicciones:\n",
      "\n",
      "0.995341424543337\n",
      "Entrenando modelo AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=0.5, n_estimators=200, random_state=None)\n",
      "Acierto en redicciones:\n",
      "\n",
      "0.928282456785583\n"
     ]
    }
   ],
   "source": [
    "classifiers = [XGBClassifier(objective='multi:softmax', n_jobs=-1),\n",
    "               RandomForestClassifier(n_estimators=200, max_depth=10, n_jobs=-1),\n",
    "               KNeighborsClassifier(n_neighbors=7, n_jobs=-1),\n",
    "               AdaBoostClassifier(n_estimators=200, learning_rate=0.5)\n",
    "              ]\n",
    "\n",
    "for clf in classifiers:\n",
    "    model = pipeline.Pipeline([\n",
    "        ('vectorizer', vectorizer),\n",
    "        ('model', clf)\n",
    "    ])\n",
    "    print('Entrenando modelo {}'.format(clf))\n",
    "    model.fit(X_train, y_train)\n",
    "    print('Acierto en redicciones:\\n')\n",
    "    preds = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora volvemos a definir nuestro mejor modelo, en este caso KNeighborsClasifier.\n",
    "\n",
    "Por supuesto, se podrían mejorar los otros modelos haciendo un *tuning* de parametros por validación cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = feature_extraction.text.TfidfVectorizer(\n",
    "    analyzer='word'\n",
    ")\n",
    "\n",
    "model = pipeline.Pipeline([\n",
    "    ('vectorizer', vectorizer),\n",
    "    ('kNN', KNeighborsClassifier(n_neighbors=7, n_jobs=-1))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya podemos entrenar nuestro modelo. Con la función *fit* entrenamos con el conjunto train, y con la función *predict* hacemos las predicciones en el conjunto test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando el modelo\n",
      "Entrenado\n",
      "Haciendo predicciones\n",
      "Predicciones realizadas\n",
      "Tiempo de entrenamiento y testeo: 6.2862 s con 27189 frases\n"
     ]
    }
   ],
   "source": [
    "t1 = time()\n",
    "\n",
    "print(\"Entrenando el modelo\")\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Entrenado\")\n",
    "\n",
    "print(\"Haciendo predicciones\")\n",
    "y_predicted = model.predict(X_test)\n",
    "print(\"Predicciones realizadas\")\n",
    "\n",
    "print(\"Tiempo de entrenamiento y testeo: %0.4f s \" % (time() - t1) +\n",
    "      \"con %0.0f frases\" % (len(df)))\n",
    "\n",
    "cm = metrics.confusion_matrix(y_test, y_predicted, labels=corpus_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos visualizar una matriz de confusión para hacer una primera comprobación tanto de los errores como de los aciertos cometidos por el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "nbpresent": {
     "id": "f2b61e38-79d5-42cd-a77f-a7f75fe55a8e"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pl</th>\n",
       "      <th>it</th>\n",
       "      <th>es</th>\n",
       "      <th>de</th>\n",
       "      <th>en</th>\n",
       "      <th>hu</th>\n",
       "      <th>pt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pl</th>\n",
       "      <td>1093</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it</th>\n",
       "      <td>2</td>\n",
       "      <td>1199</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>es</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1160</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1197</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1219</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hu</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1040</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pl    it    es    de    en    hu    pt\n",
       "pl  1093     0     2     1     3     0     0\n",
       "it     2  1199     1     0     2     0     0\n",
       "es     0     0  1160     0     1     0     4\n",
       "de     4     0     0  1197     0     0     0\n",
       "en     0     0     0     0  1219     0     0\n",
       "hu     5     0     0     0     1  1040     1\n",
       "pt     0     1    11     1     0     0  1209"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cm,index=corpus_list,columns=corpus_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver el error cometido teniendo en cuenta que los elemento de la diagonal principal son aciertos y el resto errores. Así que para evaluar nuestro modelo, sumaremos los aciertos y lo dividiremos por el número total de frases que tenemos. Ésto nos dará el porcentaje de acierto total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "nbpresent": {
     "id": "aea0ed9f-3e45-460d-8672-6e1edcf97eef"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9950962363614074"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_diag = sum(np.einsum('ii -> i', cm))\n",
    "acc = (sum_diag/len(X_test))\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También podemos ver, a través de la función *classification_report* la precisión del modelo por cada idioma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "nbpresent": {
     "id": "378a0dde-ac64-477c-9e60-1e6a45ea0d0d"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         pl       1.00      1.00      1.00      1201\n",
      "         it       0.99      1.00      1.00      1219\n",
      "         es       0.99      1.00      0.99      1165\n",
      "         de       1.00      0.99      1.00      1047\n",
      "         en       1.00      1.00      1.00      1204\n",
      "         hu       0.99      0.99      0.99      1099\n",
      "         pt       1.00      0.99      0.99      1222\n",
      "\n",
      "avg / total       1.00      1.00      1.00      8157\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, y_predicted,\n",
    "                                    target_names=corpus_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos guardar nuestras predicciones en un dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "nbpresent": {
     "id": "745d6474-4217-4941-9d75-a528a1d3e88a"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto</th>\n",
       "      <th>idioma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6350</th>\n",
       "      <td>Si tratta ora di rimuovere al più presto il le...</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22768</th>\n",
       "      <td>Ez nyilvánvalóan a jogszabály hiányossága.</td>\n",
       "      <td>hu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9973</th>\n",
       "      <td>Y los controles no deben consistir en que el i...</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13900</th>\n",
       "      <td>Es gibt ja bekanntlich ein Memorandum von Pari...</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14638</th>\n",
       "      <td>Sie muß im Blickpunkt der Öffentlichkeit stehen.</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19392</th>\n",
       "      <td>I also look forward to the White Paper which w...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22128</th>\n",
       "      <td>Nem túl nagy, és talán általában van ok az inf...</td>\n",
       "      <td>hu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21085</th>\n",
       "      <td>Hölgyeim és Uraim! A legutolsó parlamenti ülés...</td>\n",
       "      <td>hu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18887</th>\n",
       "      <td>Thank you very much, Mr Patten, for your inter...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15629</th>\n",
       "      <td>Eine solch weitgehende Taktik der verbrannten ...</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   texto idioma\n",
       "6350   Si tratta ora di rimuovere al più presto il le...     it\n",
       "22768         Ez nyilvánvalóan a jogszabály hiányossága.     hu\n",
       "9973   Y los controles no deben consistir en que el i...     es\n",
       "13900  Es gibt ja bekanntlich ein Memorandum von Pari...     de\n",
       "14638   Sie muß im Blickpunkt der Öffentlichkeit stehen.     de\n",
       "19392  I also look forward to the White Paper which w...     en\n",
       "22128  Nem túl nagy, és talán általában van ok az inf...     hu\n",
       "21085  Hölgyeim és Uraim! A legutolsó parlamenti ülés...     hu\n",
       "18887  Thank you very much, Mr Patten, for your inter...     en\n",
       "15629  Eine solch weitgehende Taktik der verbrannten ...     de"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = pd.DataFrame()\n",
    "predictions['texto'] = X_test\n",
    "predictions['idioma'] = y_predicted\n",
    "predictions[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como sabemos que en los corpus hay frases de idiomas que no corresponden al corpus donde está, podemos hacer predicciones con nuestro modelo sobre estas frases para intentar corregir los errores que hay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "nbpresent": {
     "id": "18c07fdc-d87f-4a54-b68c-781bb552b0ec"
    }
   },
   "outputs": [],
   "source": [
    "x_predicted_total = model.predict(df['texto'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos crear un nuevo dataframe con las frases de entrenamiento y la prediccion de los idiomas, para posteriormente poder hacer unas nuevas predicciones con este nuevo conjunto de entrenamiento corregido y ver si hemos conseguido mejorar el modelo o no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "nbpresent": {
     "id": "cd5d72c0-0d95-4f4a-ada5-ada46a7ded79"
    }
   },
   "outputs": [],
   "source": [
    "df_corregido = pd.DataFrame()\n",
    "df_corregido['texto'] = df['texto']\n",
    "df_corregido['idioma'] = x_predicted_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "nbpresent": {
     "id": "08e5c13e-2f6b-42f8-9749-cf1fa1eae495"
    }
   },
   "outputs": [],
   "source": [
    "X_train_new, X_test_new, y_train_new, y_test_new = cross_validation.train_test_split(\n",
    "    df_corregido['texto'],\n",
    "    df_corregido['idioma'],\n",
    "    test_size=0.3,\n",
    "    random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "nbpresent": {
     "id": "e6313469-8685-46f4-8b66-276e52f606a4"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenando el modelo\n",
      "Entrenado\n",
      "Haciendo predicciones\n",
      "Predicciones realizadas\n",
      "Tiempo de entrenamiento y testeo: 6.2221 s con 27189 frases\n"
     ]
    }
   ],
   "source": [
    "vectorizer = feature_extraction.text.TfidfVectorizer(\n",
    "    ngram_range=(0,1),\n",
    "    analyzer='word'\n",
    ")\n",
    "\n",
    "new_model = pipeline.Pipeline([\n",
    "    ('vectorizer', vectorizer),\n",
    "    ('kNN', KNeighborsClassifier(n_neighbors=7, n_jobs=-1))\n",
    "])\n",
    "\n",
    "t1 = time()\n",
    "\n",
    "print(\"Entrenando el modelo\")\n",
    "new_model.fit(X_train_new, y_train_new)\n",
    "print(\"Entrenado\")\n",
    "\n",
    "print(\"Haciendo predicciones\")\n",
    "y_predicted_new = new_model.predict(X_test_new)\n",
    "print(\"Predicciones realizadas\")\n",
    "\n",
    "print(\"Tiempo de entrenamiento y testeo: %0.4f s \" % (time() - t1) +\n",
    "      \"con %0.0f frases\" % (len(df_corregido)))\n",
    "\n",
    "cm_new = metrics.confusion_matrix(y_test_new, y_predicted_new, labels=corpus_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "nbpresent": {
     "id": "2b86d11c-1d3a-4634-936b-9241ed483383"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pl</th>\n",
       "      <th>it</th>\n",
       "      <th>es</th>\n",
       "      <th>de</th>\n",
       "      <th>en</th>\n",
       "      <th>hu</th>\n",
       "      <th>pt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pl</th>\n",
       "      <td>1103</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it</th>\n",
       "      <td>2</td>\n",
       "      <td>1198</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>es</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1174</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1197</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1226</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hu</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1039</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pt</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pl    it    es    de    en    hu    pt\n",
       "pl  1103     0     0     0     1     0     0\n",
       "it     2  1198     0     0     0     0     0\n",
       "es     0     0  1174     0     0     0     0\n",
       "de     1     0     0  1197     1     0     0\n",
       "en     0     0     0     0  1226     0     0\n",
       "hu     1     0     0     0     0  1039     0\n",
       "pt     0     0     3     0     0     0  1211"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cm_new,index=corpus_list,columns=corpus_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "nbpresent": {
     "id": "18cc41d9-4548-44ce-8aa1-d9ba3b42b4e7"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9988966531813167"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_diag_new = sum(np.einsum('ii -> i', cm_new))\n",
    "acc_new = (sum_diag_new/len(X_test_new))\n",
    "acc_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos ahora que el porcentaje de acierto ha aumentado hasta casi el 100%, por lo que hemos conseguido corregir algunos errores con esta técnica de intentar predecir sobre el mismo conjunto de entrenamiento. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "nbpresent": {
     "id": "0e4b53a1-5ca2-47d1-97e2-06fe8a063c1f"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto</th>\n",
       "      <th>idioma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6350</th>\n",
       "      <td>Si tratta ora di rimuovere al più presto il le...</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22768</th>\n",
       "      <td>Ez nyilvánvalóan a jogszabály hiányossága.</td>\n",
       "      <td>hu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9973</th>\n",
       "      <td>Y los controles no deben consistir en que el i...</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13900</th>\n",
       "      <td>Es gibt ja bekanntlich ein Memorandum von Pari...</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14638</th>\n",
       "      <td>Sie muß im Blickpunkt der Öffentlichkeit stehen.</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19392</th>\n",
       "      <td>I also look forward to the White Paper which w...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22128</th>\n",
       "      <td>Nem túl nagy, és talán általában van ok az inf...</td>\n",
       "      <td>hu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21085</th>\n",
       "      <td>Hölgyeim és Uraim! A legutolsó parlamenti ülés...</td>\n",
       "      <td>hu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18887</th>\n",
       "      <td>Thank you very much, Mr Patten, for your inter...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15629</th>\n",
       "      <td>Eine solch weitgehende Taktik der verbrannten ...</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   texto idioma\n",
       "6350   Si tratta ora di rimuovere al più presto il le...     it\n",
       "22768         Ez nyilvánvalóan a jogszabály hiányossága.     hu\n",
       "9973   Y los controles no deben consistir en que el i...     es\n",
       "13900  Es gibt ja bekanntlich ein Memorandum von Pari...     de\n",
       "14638   Sie muß im Blickpunkt der Öffentlichkeit stehen.     de\n",
       "19392  I also look forward to the White Paper which w...     en\n",
       "22128  Nem túl nagy, és talán általában van ok az inf...     hu\n",
       "21085  Hölgyeim és Uraim! A legutolsó parlamenti ülés...     hu\n",
       "18887  Thank you very much, Mr Patten, for your inter...     en\n",
       "15629  Eine solch weitgehende Taktik der verbrannten ...     de"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_predictions = pd.DataFrame()\n",
    "new_predictions['texto'] = X_test_new\n",
    "new_predictions['idioma'] = y_predicted_new\n",
    "new_predictions[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación vamos a crear una función sencilla, lo que sería el detector en sí, donde el parámetro de entrada será una frase y la salida será el idioma de dicha frase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detection(x):\n",
    "    lenguage=new_model.predict([x])\n",
    "    if lenguage == 'es':\n",
    "        lenguage = 'español'\n",
    "    elif lenguage == 'pt':\n",
    "        lenguage = 'portugués'\n",
    "    elif lenguage == 'it':\n",
    "        lenguage = 'italiano'\n",
    "    elif lenguage == 'pl':\n",
    "        lenguage = 'polaco'\n",
    "    elif lenguage == 'de':\n",
    "        lenguage = 'alemán'\n",
    "    elif lenguage == 'en':\n",
    "        lenguage = 'inglés'\n",
    "    elif lenguage == 'hu':\n",
    "        lenguage = 'húngaro'\n",
    "        \n",
    "    print('El idioma de la frase es: '+lenguage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluemos algunos ejemplos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El idioma de la frase es: español\n"
     ]
    }
   ],
   "source": [
    "detection('hola, mi nombre es Rodrigo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El idioma de la frase es: inglés\n"
     ]
    }
   ],
   "source": [
    "detection('hello, my name is Rodrigo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El idioma de la frase es: portugués\n"
     ]
    }
   ],
   "source": [
    "detection('Alguem aqui fala espanhol?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El idioma de la frase es: alemán\n"
     ]
    }
   ],
   "source": [
    "detection('Nett, Sie kennen zu lernen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El idioma de la frase es: italiano\n"
     ]
    }
   ],
   "source": [
    "detection('Piacere di conoscerla')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
